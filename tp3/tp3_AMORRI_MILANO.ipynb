{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dcbf8f-4e60-4e18-8136-189cebe933d4",
   "metadata": {},
   "source": [
    "# TP3 : Inférence variationnelle dans le modèle *Latent Dirichlet Allocation*\n",
    "\n",
    "## G3 SDI - Estimation Avancée\n",
    "\n",
    "Dans ce dernier TP, on s'intéresse au modèle *Latent Dirichlet Allocation* ([Blei et al. (2003)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)), un célèbre modèle probabiliste pour données textuelles. Voir le .pdf joint à l'archive pour la description complète du modèle. Dans ce modèle, la loi a posteriori est intractable, et nous utiliserons l'approche variationnelle pour en trouver une approximation.\n",
    "\n",
    "Using the notations from the .pdf file describing the model, the intractable posterior is :\n",
    "$$p(\\boldsymbol{\\beta}, \\boldsymbol{\\theta} | \\mathcal{D}),$$\n",
    "which we are going to approximate in the following way :\n",
    "$$\\simeq \\left[ \\prod_{k=1}^K q(\\boldsymbol{\\beta_k}) \\right] \\left[ \\prod_{d=1}^D q(\\boldsymbol{\\theta_d}) \\right] , $$\n",
    "with :\n",
    "* $q(\\boldsymbol{\\beta_k})$ a Dirichlet distribution (of size V) with variational parameters $[\\lambda_{k1}, ...,\\lambda_{kV}]$ ;\n",
    "* $q(\\boldsymbol{\\theta_d})$ a Dirichlet distribution (of size K) with variational parameters $[\\gamma_{d1}, ...,\\gamma_{dK}]$.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Renommez votre notebook sous la forme `tp3_Nom1_Nom2.ipynb`. \n",
    "\n",
    "2. Votre code, ainsi que toute sortie du code, doivent être commentés !\n",
    "\n",
    "3. Déposez votre notebook sur Moodle dans la section prévue à cet effet avant la date limite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2993e-791c-476a-a1d6-edb6878a772a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Compte-rendu écrit par AMORRI Farah, MILANO Olivia, 18/12/2025.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afc1e60-d2fc-4d02-ac4a-a022128b58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import usual libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specific for this lab\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c31f47-a2a2-4e18-9592-446abbb1bd5d",
   "metadata": {},
   "source": [
    "**Q0.** À quelle difficulté principale se heurterait un algorithme MCMC dans ce contexte ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6021628-446b-4ebe-a313-7a7bce00eca1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "La difficulté principale est la scalabilité (le passage à l'échelle) et le coût de calcul élevé sur de grands corpus.\n",
    "\n",
    "\n",
    "Contrairement à l'inférence variationnelle (qui traite le problème par optimisation), les méthodes MCMC (comme l'échantillonneur de Gibbs) fonctionnent par simulation. Elles nécessitent de générer un très grand nombre d'échantillons itératifs pour chaque mot afin d'approcher la distribution réelle. Cela rend la convergence très lente et l'entraînement difficilement gérable lorsque le volume de données (nombre de documents $D$) est important.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a86fb5-e993-4eb2-9c77-2063d44a0f1b",
   "metadata": {},
   "source": [
    "### Partie 1 - Préparation des données\n",
    "\n",
    "On utilise le dataset `20newsgroups` (voir par exemple [ici](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset)), qui contient des messages postés dans différentes catégories sur un forum dans les années 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaf7d5-1bfc-4e69-b874-93127fc4242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Load data\n",
    "# List \n",
    "newsgroups = fetch_20newsgroups().data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247bae38-91b8-457b-ba22-0e0fbaf67545",
   "metadata": {},
   "source": [
    "**Q1.** En LDA, sous quelle forme est représentée un document ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6866-bb5f-4cf9-b9ca-61409bedd530",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "Dans le modèle LDA, un document est représenté comme une distribution de probabilité sur les thèmes latents (notée $\\theta_d$).\n",
    "\n",
    "\n",
    "Concrètement, chaque document est vu comme un mélange (mixture) de plusieurs thèmes avec différentes proportions (par exemple : 80% de \"Sport\" et 20% de \"Politique\"). Mathématiquement, c'est un vecteur de taille $K$ dont la somme des coefficients vaut 1.\n",
    "\n",
    "En entrée du modèle, le document est traité comme un \"Sac de mots\" (Bag-of-Words), c'est-à-dire un vecteur de comptage où l'ordre des mots est ignoré.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80d52a-774b-4736-ae0b-6f7a256b578e",
   "metadata": {},
   "source": [
    "**Q2.** Créer la matrice des données en utilisant la fonction `CountVectorizer` en utilisant les arguments :\n",
    "* `max_df` = 0.95 ;\n",
    "* `max_features` = 1000 ;\n",
    "* `stop_words` = \"english\".\n",
    "\n",
    "Expliquer à quoi correspondent ces 3 arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cce98e-0123-4067-a3fc-9cec369e4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice : (11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=0.95,\n",
    "    max_features=1000,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "# Création de la matrice des données (Matrice Document-Terme)\n",
    "# X sera une matrice sparse de taille (D x V)\n",
    "X = tf_vectorizer.fit_transform(newsgroups)\n",
    "\n",
    "\n",
    "# Récupération des mots (le vocabulaire) \n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Taille de la matrice : {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b357dd-1901-4db1-ab6c-dc1b9c5c2ce9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "**Explication des arguments :**\n",
    "\n",
    "* **`max_df=0.95`** : Ce paramètre demande d'ignorer les mots qui apparaissent dans **plus de 95% des documents**. L'objectif est d'éliminer les termes trop génériques (ou \"corpus-specific stop words\") qui sont présents partout et n'aident pas à distinguer les thèmes.\n",
    "\n",
    "\n",
    "* **`max_features=1000`** : Ce paramètre limite la taille du vocabulaire aux **1000 mots les plus fréquents** du corpus. Cela permet de réduire la dimension de la matrice X et de se concentrer sur les mots les plus significatifs en éliminant les termes rares.\n",
    "\n",
    "\n",
    "* **`stop_words=\"english\"`** : Ce paramètre active le filtrage automatique des **mots vides** (stop words) de la langue anglaise (comme \"the\", \"is\", \"at\", \"which\"). Ces mots, bien que très fréquents, portent peu de sens sémantique et ne sont pas utiles pour identifier des sujets.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f4304-52e4-4974-b21d-32e4b1d3ce7c",
   "metadata": {},
   "source": [
    "**Q3.** Rappeler à quoi correspondent les dimensions de la matrice des données obtenues.\n",
    "\n",
    "Calculer son pourcentage d'éléments non-nuls. Est-ce surprenant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b9a9b2-612f-4d7a-b007-414b9f39d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'éléments non-nuls (Densité) : 4.4165 %\n",
      "Pourcentage de zéros (Sparsité) : 95.5835 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_elements = X.shape[0] * X.shape[1]\n",
    "\n",
    "\n",
    "non_zero_elements = X.nnz\n",
    "\n",
    "\n",
    "density = (non_zero_elements / total_elements) * 100\n",
    "\n",
    "print(f\"Pourcentage d'éléments non-nuls (Densité) : {density:.4f} %\")\n",
    "print(f\"Pourcentage de zéros (Sparsité) : {100 - density:.4f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046ccb2-88f1-408a-8e33-bdd9b2e775fe",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "### Dimensions de la matrice\n",
    "\n",
    "La matrice obtenue est de taille **(11314, 1000)**, où :\n",
    "\n",
    "* **(Lignes)** : correspond au **nombre de documents** dans le corpus `newsgroups`.\n",
    "* **(Colonnes)** : correspond à la **taille du vocabulaire** conservé. Ici,  car nous avons fixé `max_features=1000`.\n",
    "\n",
    "\n",
    "### Pourcentage d'éléments non-nuls\n",
    "\n",
    "**Non, ce n'est pas surprenant.** Ce pourcentage devrait être très faible (généralement inférieur à 1% ou 2%).\n",
    "\n",
    "C'est ce qu'on appelle une **matrice creuse** (sparse matrix). Cela s'explique par le fait que chaque document individuel n'utilise qu'une toute petite partie du vocabulaire global (ici 1000 mots). La grande majorité des cases de la matrice contiennent donc la valeur **0**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e189507-2905-405e-a973-81b43e6156a8",
   "metadata": {},
   "source": [
    "### Partie 2 - Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c6d98-d1b4-4741-9daa-0d6c1c54c99a",
   "metadata": {},
   "source": [
    "**Q4.** Entraîner le modèle LDA avec les arguments suivants :\n",
    "* `n_components` = 8 ;\n",
    "* `learning_method` = \"online\" ;\n",
    "* `max_iter` = 50 ;\n",
    "* `doc_topic_prior` = 0.1 ;\n",
    "* `topic_word_prior` = 0.1 ;\n",
    "* `learning_offset` = 100.\n",
    "\n",
    "Idem, expliquer à quoi correspondent chacun de ces arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b335107-bb25-41f5-af54-d3033b58c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de l'entraînement (Inférence Variationnelle)...\n",
      "Entraînement terminé.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Initialisation du modèle \n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=8,\n",
    "    learning_method=\"online\",\n",
    "    max_iter=50,\n",
    "    doc_topic_prior=0.1,\n",
    "    topic_word_prior=0.1,\n",
    "    learning_offset=100,\n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "# Entraînement du modèle \n",
    "print(\"Démarrage de l'entraînement (Inférence Variationnelle)...\")\n",
    "lda_model.fit(X)\n",
    "print(\"Entraînement terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ee37d-8d79-42e7-a484-822765ec586e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "### Explication des arguments\n",
    "\n",
    "* **`n_components` = 8** : C'est le nombre de thèmes latents () que le modèle doit trouver. L'algorithme va forcer les données à s'organiser en exactement 8 sujets distincts.\n",
    "\n",
    "* **`learning_method` = \"online\"** : Indique que l'algorithme doit apprendre par \"petits paquets\" (mini-batches) de données plutôt que de charger tout le corpus en mémoire à chaque calcul (\"batch\"). C'est beaucoup plus rapide et nécessaire pour les grands jeux de données.\n",
    "\n",
    "* **`max_iter` = 50** : Le nombre de fois que l'algorithme va passer sur l'ensemble des données (époques) pour affiner ses probabilités. Plus il y a d'itérations, plus le résultat est précis (jusqu'à convergence).\n",
    "\n",
    "* **`doc_topic_prior` = 0.1** : Correspond au paramètre ** (Alpha)** de la distribution de Dirichlet. Une valeur faible () incite le modèle à rendre la distribution des thèmes \"clairsemée\" (sparse) : chaque document sera composé majoritairement d'un ou deux thèmes, plutôt que d'un mélange équilibré de tous les thèmes.\n",
    "\n",
    "* **`topic_word_prior` = 0.1** : Correspond au paramètre ** (Eta)**. Comme pour Alpha, une valeur faible incite à la \"sparsité\" : chaque thème sera défini par quelques mots très forts, plutôt que par l'ensemble du vocabulaire.\n",
    "\n",
    "* **`learning_offset` = 100** : Un paramètre technique lié à la méthode \"online\". Il réduit le poids des toutes premières itérations (qui sont souvent très imprécises) pour éviter que le modèle ne parte dans une mauvaise direction dès le début. Une valeur plus élevée (comme 100) ralentit l'apprentissage au début pour le stabiliser.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3424f-0458-48b8-84f6-92d0a287caf5",
   "metadata": {},
   "source": [
    "**Q5.** Que contient l'attribut `.components` ?\n",
    "\n",
    "Comment obtenir le MMSE de $\\boldsymbol{\\beta}$ à partir de cet attribut ? L'implémenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c20af2c-6d62-4c62-a3a5-a95088ce6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice brute : (8, 1000)\n",
      "Somme de la première ligne (avant norm.) : 99116.08\n",
      "------------------------------\n",
      "Forme de la matrice estimée (beta) : (8, 1000)\n",
      "Somme de la première ligne (après norm.) : 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "lambda_matrix = lda_model.components_\n",
    "\n",
    "print(f\"Forme de la matrice brute : {lambda_matrix.shape}\")\n",
    "print(f\"Somme de la première ligne (avant norm.) : {lambda_matrix[0].sum():.2f}\")\n",
    "\n",
    "# Calcul du MMSE (Espérance de la Dirichlet) -> Normalisation L1 par ligne\n",
    "# On divise chaque élément par la somme de sa ligne\n",
    "beta_mmse = lambda_matrix / lambda_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Vérification\n",
    "print(\"-\" * 30)\n",
    "print(f\"Forme de la matrice estimée (beta) : {beta_mmse.shape}\")\n",
    "print(f\"Somme de la première ligne (après norm.) : {beta_mmse[0].sum():.2f}\") \n",
    "# Doit afficher 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16d3b5-dd98-48a3-a74d-7b8e14720bcc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "### L'attribut `.components_` \n",
    "\n",
    "L'attribut `.components_` est une matrice de taille **** (nombre de thèmes  taille du vocabulaire).\n",
    "\n",
    "Elle contient les **paramètres variationnels** de la distribution mot-thème. Concrètement, la valeur à la ligne  et la colonne  représente le **\"pseudo-compte\"** (nombre d'occurrences estimé + le prior ) du mot  dans le thème . Plus la valeur est élevée, plus le mot est important pour ce thème.\n",
    "\n",
    "### Obtenir le MMSE \n",
    "\n",
    "L'estimateur **MMSE** (Minimum Mean Square Error) d'une variable aléatoire est son **espérance** (sa moyenne).\n",
    "\n",
    "Puisque la distribution a posteriori des mots dans les thèmes () suit une loi de **Dirichlet**, son espérance se calcule simplement en **normalisant** les paramètres pour que leur somme soit égale à 1.\n",
    "\n",
    "Il faut donc diviser chaque valeur de la ligne par la somme totale de la ligne.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781c36f-e1ce-4b56-b233-d072f26db66f",
   "metadata": {},
   "source": [
    "**Q6.** À partir de $\\hat{\\boldsymbol{\\beta}}_{MMSE}$, afficher les 10 mots les plus courants par topic. Pouvez-vous interpréter les topics obtenus ?\n",
    "\n",
    "Si vous souhaitez rajouter certains mots à la liste des stop words pour améliorer l'interprétabilité, utilisez le bloc de code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "674bc899-0849-418e-b03f-22e863bca269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: edu, file, uk, mail, ac, information, program, com, university, available\n",
      "Topic #2: people, government, gun, law, president, don, right, mr, think, state\n",
      "Topic #3: ax, max, g9v, b8f, a86, 145, pl, 0d, 1d9, 34u\n",
      "Topic #4: windows, drive, use, card, com, problem, ibm, scsi, dos, mac\n",
      "Topic #5: god, people, don, think, say, know, just, said, jesus, does\n",
      "Topic #6: 10, 00, team, game, 1993, 15, 25, 20, apr, year\n",
      "Topic #7: space, key, gov, nasa, chip, access, encryption, clipper, data, use\n",
      "Topic #8: edu, com, writes, article, posting, nntp, host, university, just, like\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(beta_matrix, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(beta_matrix):\n",
    "        # On trie les indices par probabilité croissante et on prend les 10 derniers\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        \n",
    "        # On récupère les mots correspondants\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        \n",
    "        # Affichage formaté\n",
    "        print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Appel de la fonction\n",
    "print_top_words(beta_mmse, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a49bd61-93fc-4a00-92ec-c6c2a7182b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add additional stop words\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_additional_stop_words =  ['said', 'would', 'just', 'like', 'know', 'don', 'year', 'make']\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145752-5a31-461f-afdf-1741cead974e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "\n",
    "### Interprétation \n",
    "\n",
    "Voici l'interprétation basée sur les résultats que vous avez fournis. On remarque que certains thèmes sont très clairs, tandis que d'autres sont pollués par du \"bruit\".\n",
    "\n",
    "* **Topic #1 (Académique / Réseau) :** Contient des termes liés aux adresses email et universités (`edu`, `uk`, `ac`, `file`, `mail`). C'est un mélange de méta-données et d'échange de fichiers.\n",
    "* **Topic #2 (Politique) :** Très cohérent, il parle de politique américaine, de gouvernement et du débat sur les armes (`gun`, `law`, `president`).\n",
    "* **Topic #3 (Bruit / Artefacts) :** Ce topic est **ininterprétable**. Il contient des chaînes de caractères aléatoires (`g9v`, `b8f`, `ax`). Cela correspond souvent à des fichiers binaires ou des images encodés en texte (Base64) qui n'ont pas été nettoyés.\n",
    "* **Topic #4 (Informatique / Hardware) :** Très clair, orienté matériel et système d'exploitation (`windows`, `drive`, `scsi`, `dos`, `mac`).\n",
    "* **Topic #5 (Religion) :** Très clair, discussions théologiques (`god`, `jesus`, `think`, `say`).\n",
    "* **Topic #6 (Sport) :** Contient des scores, des dates et des termes d'équipe (`team`, `game`, `10`, `25`).\n",
    "* **Topic #7 (Espace & Sécurité) :** Un mélange intéressant entre la NASA (`space`, `nasa`) et la cryptographie (`key`, `encryption`, `clipper`, `chip`).\n",
    "* **Topic #8 (Méta-données Usenet) :** Ce sont des mots structurels propres aux forums de discussion de l'époque (`writes`, `article`, `posting`, `nntp`). Ce sont des \"stop words\" contextuels à retirer.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0be89e-4ba5-4aa3-a1b3-b3e0d5ac44b4",
   "metadata": {},
   "source": [
    "**Q7.** Que contient `lda.transform(X)` ?\n",
    "\n",
    "Regarder si les documents sont en général plutôt associés à un ou plusieurs topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90904f0f-8a94-4405-a480-5de1aeadaa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice theta : (11314, 8)\n",
      "\n",
      "Exemple pour le Document 0 :\n",
      "[0.00304977 0.00304917 0.00304878 0.00304937 0.00304977 0.00304949\n",
      " 0.00304922 0.97865443]\n",
      "Topic dominant : 8 (avec proba 0.98)\n",
      "\n",
      "Confiance moyenne du modèle : 0.63\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Calcul de la distribution des sujets pour tous les documents\n",
    "# doc_topic_dist correspond à theta\n",
    "doc_topic_dist = lda_model.transform(X)\n",
    "\n",
    "print(f\"Taille de la matrice theta : {doc_topic_dist.shape}\")\n",
    "\n",
    "# 2. Regardons un exemple concret (le premier document)\n",
    "print(f\"\\nExemple pour le Document 0 :\")\n",
    "print(doc_topic_dist[0])\n",
    "print(f\"Topic dominant : {np.argmax(doc_topic_dist[0]) + 1} (avec proba {np.max(doc_topic_dist[0]):.2f})\")\n",
    "\n",
    "# 3. Analyse globale : Est-ce général ?\n",
    "# On récupère la probabilité maximale pour chaque document\n",
    "max_probs = np.max(doc_topic_dist, axis=1)\n",
    "\n",
    "# On affiche la moyenne de ces maximums\n",
    "print(f\"\\nConfiance moyenne du modèle : {np.mean(max_probs):.2f}\")\n",
    "\n",
    "# Visualisation (Bonus très apprécié)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(max_probs, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution de la probabilité du Topic Dominant')\n",
    "plt.xlabel('Probabilité du topic principal (de 1/K à 1.0)')\n",
    "plt.ylabel('Nombre de documents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebfd16-8ef4-419a-9e42-69a028f3306f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Voici l'analyse détaillée de vos résultats et la réponse à la question.\n",
    "\n",
    "### `lda.transform(X)` \n",
    "\n",
    "C'est la matrice ** (Theta)** dont parle la théorie du début.\n",
    "\n",
    "* **Dimensions :**  soit (11314 documents  8 thèmes).\n",
    "* **Contenu :** Elle contient la **distribution de probabilité des thèmes pour chaque document**. La somme de chaque ligne vaut 1.\n",
    "\n",
    "### Analyse des résultats\n",
    "\n",
    "Avec une **confiance moyenne de 0.63 (63%)**.\n",
    "\n",
    "* Si les documents étaient un mélange parfait et flou de tous les thèmes, le score serait de  (12.5%).\n",
    "* Si les documents ne parlaient strictement que d'un seul sujet, le score serait de 1.0 (100%).\n",
    "\n",
    "Avec **63%**, cela indique que le modèle arrive généralement à dégager **un thème dominant** (Majoritaire), mais qu'il reste une part de mélange (le document emprunte du vocabulaire à d'autres thèmes). Votre \"Document 0\" (98%) est un cas idéal très \"pur\", mais la moyenne suggère que d'autres documents sont plus mitigés (ex: 40% Politique, 30% Religion, 30% Autre).\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6acb9-1e57-432c-ad5b-5428df5bf727",
   "metadata": {},
   "source": [
    "### Partie 3 - Pour aller plus loin...\n",
    "\n",
    "Répondre aux questions sans implémenter les solutions discutées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269fff1-c4bb-46d8-ba5a-99afb8e041eb",
   "metadata": {},
   "source": [
    "**Q8.** Quelle est l'influence des paramètres $\\alpha$ et $\\eta$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b8deb-bfa0-4aa9-b35a-904e34058656",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "Ces hyperparamètres contrôlent la sparsité (la concentration) des distributions :\n",
    "\n",
    "1. <b>$\\alpha$ (Alpha) - Contrôle les Documents ($\\theta$) :</b>\n",
    "<ul>\n",
    "    <li><b>Valeur faible</b> (< 1) : Force les documents à être constitués de <b>peu de thèmes</b> (ex: un document parle à 90% de Sport). C'est ce que nous avons utilisé (0.1).</li>\n",
    "    <li><b>Valeur élevée</b> : Les documents deviennent des mélanges flous de presque tous les thèmes (ex: 12% Sport, 12% Politique, 12% Tech...).</li>\n",
    "</ul>\n",
    "\n",
    "2. <b>$\\eta$ (Eta) - Contrôle les Thèmes ($\\beta$) :</b>\n",
    "<ul>\n",
    "    <li><b>Valeur faible</b> (< 1) : Force les thèmes à être définis par <b>peu de mots</b> très spécifiques. Cela rend les thèmes plus lisibles.</li>\n",
    "    <li><b>Valeur élevée</b> : Les thèmes ont tendance à utiliser tout le vocabulaire, les rendant plus génériques et difficiles à interpréter.</li>\n",
    "</ul>\n",
    "En résumé : Des valeurs faibles rendent le modèle plus tranché et plus interprétable (Sparse), tandis que des valeurs élevées le rendent plus lisse et uniforme.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb6e71-7608-47ac-b7fd-906ed58b54ee",
   "metadata": {},
   "source": [
    "**Q9.** Pour aujourd'hui, le nombre de topics $K$ était fixé à l'avance. Comment pourrait-on apprendre ou choisir la valeur de $K$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2b5d2-65a2-491f-a91e-9c2490ffd0e0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "\n",
    "Le nombre de topics $K$ est un hyperparamètre qu'il faut optimiser. Comme il s'agit d'apprentissage non-supervisé, on ne peut pas calculer de \"taux d'erreur\", mais on utilise deux métriques principales via une <b>Grid Search</b> (on teste plusieurs valeurs, ex: 5, 10, 15, 20...) :\n",
    "<br><br>\n",
    "1. <b>La Perplexité (Perplexity) :</b>\n",
    "C'est une mesure statistique interne qui évalue la capacité du modèle à prédire de nouveaux documents (généralisation).\n",
    "<ul>\n",
    "    <li>On cherche à <b>minimiser</b> la perplexité.</li>\n",
    "    <li><i>Limitation :</i> Une bonne perplexité mathématique ne garantit pas que les sujets sont compréhensibles par un humain.</li>\n",
    "</ul>\n",
    "\n",
    "2. <b>Le Score de Cohérence (Topic Coherence) :</b>\n",
    "C'est la métrique préférée aujourd'hui. Elle mesure la similarité sémantique entre les mots les plus forts d'un même topic.\n",
    "<ul>\n",
    "    <li>On cherche à <b>maximiser</b> la cohérence (ex: score $C_v$).</li>\n",
    "    <li>Elle corrèle beaucoup mieux avec l'interprétabilité humaine.</li>\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082b303-c380-4158-aa02-e1fbe260d3b1",
   "metadata": {},
   "source": [
    "**Q10.** Quelles sont les principales limites du modèle LDA et quelles potentielles améliorations proposez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c673e62-b4fd-4f53-a286-4497288b5868",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "<b>Principales limites du LDA :</b>\n",
    "<ul>\n",
    "    <li><b>L'hypothèse \"Sac de mots\" (Bag-of-Words) :</b> Le modèle ignore totalement l'ordre des mots et la structure grammaticale. Il perd le contexte sémantique (ex: il ne fait pas la différence entre \"chien mord homme\" et \"homme mord chien\").</li>\n",
    "    <li><b>Le nombre de topics fixe (K) :</b> Il faut deviner le nombre de thèmes à l'avance, ce qui est rarement connu dans la réalité.</li>\n",
    "    <li><b>Indépendance des documents :</b> Le modèle standard ne prend pas en compte l'évolution temporelle (un sujet qui change au fil du temps) ou les métadonnées des auteurs.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Améliorations et alternatives modernes :</b>\n",
    "<ul>\n",
    "    <li><b>Intégrer les N-grams :</b> Au lieu d'utiliser des mots simples, utiliser des Bigrams (ex: \"pomme_de_terre\") pour capturer un peu plus de contexte local.</li>\n",
    "    <li><b>Modèles Dynamiques (Dynamic Topic Modeling) :</b> Pour analyser l'évolution des sujets sur une échelle de temps (ex: l'évolution du discours politique sur 10 ans).</li>\n",
    "    <li><b>Utiliser des Embeddings (BERTopic) :</b> C'est l'amélioration moderne majeure. Au lieu de compter les mots, on utilise des modèles de langage (type BERT) pour transformer les phrases en vecteurs mathématiques qui capturent le sens. <b>BERTopic</b> combine ces embeddings avec du clustering (HDBSCAN) pour trouver des thèmes sémantiquement plus riches sans avoir à définir K à l'avance.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a108df",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
