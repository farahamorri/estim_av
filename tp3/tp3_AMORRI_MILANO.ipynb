{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dcbf8f-4e60-4e18-8136-189cebe933d4",
   "metadata": {},
   "source": [
    "# TP3 : Inférence variationnelle dans le modèle *Latent Dirichlet Allocation*\n",
    "\n",
    "## G3 SDI - Estimation Avancée\n",
    "\n",
    "Dans ce dernier TP, on s'intéresse au modèle *Latent Dirichlet Allocation* ([Blei et al. (2003)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)), un célèbre modèle probabiliste pour données textuelles. Voir le .pdf joint à l'archive pour la description complète du modèle. Dans ce modèle, la loi a posteriori est intractable, et nous utiliserons l'approche variationnelle pour en trouver une approximation.\n",
    "\n",
    "Using the notations from the .pdf file describing the model, the intractable posterior is :\n",
    "$$p(\\boldsymbol{\\beta}, \\boldsymbol{\\theta} | \\mathcal{D}),$$\n",
    "which we are going to approximate in the following way :\n",
    "$$\\simeq \\left[ \\prod_{k=1}^K q(\\boldsymbol{\\beta_k}) \\right] \\left[ \\prod_{d=1}^D q(\\boldsymbol{\\theta_d}) \\right] , $$\n",
    "with :\n",
    "* $q(\\boldsymbol{\\beta_k})$ a Dirichlet distribution (of size V) with variational parameters $[\\lambda_{k1}, ...,\\lambda_{kV}]$ ;\n",
    "* $q(\\boldsymbol{\\theta_d})$ a Dirichlet distribution (of size K) with variational parameters $[\\gamma_{d1}, ...,\\gamma_{dK}]$.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Renommez votre notebook sous la forme `tp3_Nom1_Nom2.ipynb`. \n",
    "\n",
    "2. Votre code, ainsi que toute sortie du code, doivent être commentés !\n",
    "\n",
    "3. Déposez votre notebook sur Moodle dans la section prévue à cet effet avant la date limite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2993e-791c-476a-a1d6-edb6878a772a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Compte-rendu écrit par AMORRI Farah, MILANO Olivia, 18/12/2025.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afc1e60-d2fc-4d02-ac4a-a022128b58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import usual libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specific for this lab\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c31f47-a2a2-4e18-9592-446abbb1bd5d",
   "metadata": {},
   "source": [
    "**Q0.** À quelle difficulté principale se heurterait un algorithme MCMC dans ce contexte ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6021628-446b-4ebe-a313-7a7bce00eca1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a86fb5-e993-4eb2-9c77-2063d44a0f1b",
   "metadata": {},
   "source": [
    "### Partie 1 - Préparation des données\n",
    "\n",
    "On utilise le dataset `20newsgroups` (voir par exemple [ici](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset)), qui contient des messages postés dans différentes catégories sur un forum dans les années 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaf7d5-1bfc-4e69-b874-93127fc4242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Load data\n",
    "newsgroups = fetch_20newsgroups().data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247bae38-91b8-457b-ba22-0e0fbaf67545",
   "metadata": {},
   "source": [
    "**Q1.** En LDA, sous quelle forme est représentée un document ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6866-bb5f-4cf9-b9ca-61409bedd530",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80d52a-774b-4736-ae0b-6f7a256b578e",
   "metadata": {},
   "source": [
    "**Q2.** Créer la matrice des données en utilisant la fonction `CountVectorizer` en utilisant les arguments :\n",
    "* `max_df` = 0.95 ;\n",
    "* `max_features` = 1000 ;\n",
    "* `stop_words` = \"english\".\n",
    "\n",
    "Expliquer à quoi correspondent ces 3 arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cce98e-0123-4067-a3fc-9cec369e4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice : (11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Création de l'instance CountVectorizer avec les paramètres demandés\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=0.95,\n",
    "    max_features=1000,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "# Création de la matrice des données (Matrice Document-Terme)\n",
    "# X sera une matrice sparse de taille (D x V)\n",
    "X = tf_vectorizer.fit_transform(newsgroups)\n",
    "\n",
    "# Récupération des noms des mots (le vocabulaire) pour vérification\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Taille de la matrice : {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b357dd-1901-4db1-ab6c-dc1b9c5c2ce9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f4304-52e4-4974-b21d-32e4b1d3ce7c",
   "metadata": {},
   "source": [
    "**Q3.** Rappeler à quoi correspondent les dimensions de la matrice des données obtenues.\n",
    "\n",
    "Calculer son pourcentage d'éléments non-nuls. Est-ce surprenant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9a9b2-612f-4d7a-b007-414b9f39d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'éléments non-nuls (Densité) : 4.4165 %\n",
      "Pourcentage de zéros (Sparsité) : 95.5835 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_elements = X.shape[0] * X.shape[1]\n",
    "\n",
    "\n",
    "non_zero_elements = X.nnz\n",
    "\n",
    "\n",
    "density = (non_zero_elements / total_elements) * 100\n",
    "\n",
    "print(f\"Pourcentage d'éléments non-nuls (Densité) : {density:.4f} %\")\n",
    "print(f\"Pourcentage de zéros (Sparsité) : {100 - density:.4f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046ccb2-88f1-408a-8e33-bdd9b2e775fe",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e189507-2905-405e-a973-81b43e6156a8",
   "metadata": {},
   "source": [
    "### Partie 2 - Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c6d98-d1b4-4741-9daa-0d6c1c54c99a",
   "metadata": {},
   "source": [
    "**Q4.** Entraîner le modèle LDA avec les arguments suivants :\n",
    "* `n_components` = 8 ;\n",
    "* `learning_method` = \"online\" ;\n",
    "* `max_iter` = 50 ;\n",
    "* `doc_topic_prior` = 0.1 ;\n",
    "* `topic_word_prior` = 0.1 ;\n",
    "* `learning_offset` = 100.\n",
    "\n",
    "Idem, expliquer à quoi correspondent chacun de ces arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b335107-bb25-41f5-af54-d3033b58c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de l'entraînement (Inférence Variationnelle)...\n",
      "Entraînement terminé.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Initialisation du modèle avec les hyperparamètres demandés\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=8,\n",
    "    learning_method=\"online\",\n",
    "    max_iter=50,\n",
    "    doc_topic_prior=0.1,\n",
    "    topic_word_prior=0.1,\n",
    "    learning_offset=100,\n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "# Entraînement du modèle sur la matrice des données X (calculée en Q2)\n",
    "print(\"Démarrage de l'entraînement (Inférence Variationnelle)...\")\n",
    "lda_model.fit(X)\n",
    "print(\"Entraînement terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ee37d-8d79-42e7-a484-822765ec586e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3424f-0458-48b8-84f6-92d0a287caf5",
   "metadata": {},
   "source": [
    "**Q5.** Que contient l'attribut `.components` ?\n",
    "\n",
    "Comment obtenir le MMSE de $\\boldsymbol{\\beta}$ à partir de cet attribut ? L'implémenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c20af2c-6d62-4c62-a3a5-a95088ce6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice brute : (8, 1000)\n",
      "Somme de la première ligne (avant norm.) : 99116.08\n",
      "------------------------------\n",
      "Forme de la matrice estimée (beta) : (8, 1000)\n",
      "Somme de la première ligne (après norm.) : 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "lambda_matrix = lda_model.components_\n",
    "\n",
    "print(f\"Forme de la matrice brute : {lambda_matrix.shape}\")\n",
    "print(f\"Somme de la première ligne (avant norm.) : {lambda_matrix[0].sum():.2f}\")\n",
    "\n",
    "# Calcul du MMSE (Espérance de la Dirichlet) -> Normalisation L1 par ligne\n",
    "# On divise chaque élément par la somme de sa ligne\n",
    "beta_mmse = lambda_matrix / lambda_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Vérification\n",
    "print(\"-\" * 30)\n",
    "print(f\"Forme de la matrice estimée (beta) : {beta_mmse.shape}\")\n",
    "print(f\"Somme de la première ligne (après norm.) : {beta_mmse[0].sum():.2f}\") \n",
    "# Doit afficher 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16d3b5-dd98-48a3-a74d-7b8e14720bcc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781c36f-e1ce-4b56-b233-d072f26db66f",
   "metadata": {},
   "source": [
    "**Q6.** À partir de $\\hat{\\boldsymbol{\\beta}}_{MMSE}$, afficher les 10 mots les plus courants par topic. Pouvez-vous interpréter les topics obtenus ?\n",
    "\n",
    "Si vous souhaitez rajouter certains mots à la liste des stop words pour améliorer l'interprétabilité, utilisez le bloc de code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674bc899-0849-418e-b03f-22e863bca269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: edu, file, uk, mail, ac, information, program, com, university, available\n",
      "Topic #2: people, government, gun, law, president, don, right, mr, think, state\n",
      "Topic #3: ax, max, g9v, b8f, a86, 145, pl, 0d, 1d9, 34u\n",
      "Topic #4: windows, drive, use, card, com, problem, ibm, scsi, dos, mac\n",
      "Topic #5: god, people, don, think, say, know, just, said, jesus, does\n",
      "Topic #6: 10, 00, team, game, 1993, 15, 25, 20, apr, year\n",
      "Topic #7: space, key, gov, nasa, chip, access, encryption, clipper, data, use\n",
      "Topic #8: edu, com, writes, article, posting, nntp, host, university, just, like\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(beta_matrix, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(beta_matrix):\n",
    "        # On trie les indices par probabilité croissante et on prend les 10 derniers\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        \n",
    "        # On récupère les mots correspondants\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        \n",
    "        # Affichage formaté\n",
    "        print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "# Récupération du vocabulaire (si ce n'est pas déjà fait)\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Appel de la fonction\n",
    "print_top_words(beta_mmse, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49bd61-93fc-4a00-92ec-c6c2a7182b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add additional stop words\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_additional_stop_words = ### YOUR LIST HERE ### #list of strings\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145752-5a31-461f-afdf-1741cead974e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0be89e-4ba5-4aa3-a1b3-b3e0d5ac44b4",
   "metadata": {},
   "source": [
    "**Q7.** Que contient `lda.transform(X)` ?\n",
    "\n",
    "Regarder si les documents sont en général plutôt associés à un ou plusieurs topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90904f0f-8a94-4405-a480-5de1aeadaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "### YOUR CODE HERE\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebfd16-8ef4-419a-9e42-69a028f3306f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6acb9-1e57-432c-ad5b-5428df5bf727",
   "metadata": {},
   "source": [
    "### Partie 3 - Pour aller plus loin...\n",
    "\n",
    "Répondre aux questions sans implémenter les solutions discutées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269fff1-c4bb-46d8-ba5a-99afb8e041eb",
   "metadata": {},
   "source": [
    "**Q8.** Quelle est l'influence des paramètres $\\alpha$ et $\\eta$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b8deb-bfa0-4aa9-b35a-904e34058656",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb6e71-7608-47ac-b7fd-906ed58b54ee",
   "metadata": {},
   "source": [
    "**Q9.** Pour aujourd'hui, le nombre de topics $K$ était fixé à l'avance. Comment pourrait-on apprendre ou choisir la valeur de $K$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2b5d2-65a2-491f-a91e-9c2490ffd0e0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082b303-c380-4158-aa02-e1fbe260d3b1",
   "metadata": {},
   "source": [
    "**Q10.** Quelles sont les principales limites du modèle LDA et quelles potentielles améliorations proposez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c673e62-b4fd-4f53-a286-4497288b5868",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(255, 255, 0, 0.15); padding: 8px;\">\n",
    "Votre réponse ici\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
